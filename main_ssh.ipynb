{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647672d-1730-49ce-9285-d8f54074888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote Training on SSH with CUDA\n",
    "\n",
    "This notebook lets you launch training on an SSH machine with CUDA and safely disconnect while training continues.\n",
    "\n",
    "**How it works:**\n",
    "- Cell 2: Launches training as a background process with `nohup` (survives SSH disconnect)\n",
    "- Cell 3: Monitor recent training logs\n",
    "- Cell 4: Check GPU utilization\n",
    "- Cell 5: Stop training if needed\n",
    "\n",
    "**Workflow:**\n",
    "1. Run Cell 2 to start training\n",
    "2. Disconnect from SSH/close notebook - training continues!\n",
    "3. Reconnect later and run Cell 3 to check progress\n",
    "4. Check outputs in `checkpoints/` and `outputs/` directories when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce32ba6-caa8-47de-ada5-2ab1cf456a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training in background...\n",
      "Logs will be written to: logs/training_20260115_184556.log\n",
      "To monitor progress: tail -f logs/training_20260115_184556.log\n",
      "To check if still running: ps aux | grep 'python main.py'\n",
      "\n",
      "✓ Training launched in background!\n",
      "\n",
      "Useful commands:\n",
      "  Monitor live:     tail -f logs/training_20260115_184556.log\n",
      "  Check status:     ps aux | grep 'python main.py'\n",
      "  Kill if needed:   pkill -f 'python main.py'\n",
      "  GPU usage:        nvidia-smi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.2)\n",
      "[0.         0.00436332 0.00872665 0.01308997 0.01745329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 18:45:57 - INFO - ================================================================================\n",
      "2026-01-15 18:45:57 - INFO - SARRP CBCT GPU Reconstruction\n",
      "2026-01-15 18:45:57 - INFO - ================================================================================\n",
      "2026-01-15 18:45:57 - INFO - ✓ GPU acceleration enabled (CuPy)\n",
      "2026-01-15 18:45:57 - INFO - \n",
      "2026-01-15 18:45:57 - INFO - Step 1: Loading geometry...\n",
      "2026-01-15 18:45:57 - INFO -   Geometry: SOD=353.27 mm, SDD=634.00 mm, IDD=280.73 mm\n",
      "2026-01-15 18:45:57 - INFO -   Detector: 1024 × 1024 pixels\n",
      "2026-01-15 18:45:57 - INFO -   Projections: 1440 angles from 0.0° to 360.0°\n",
      "2026-01-15 18:45:57 - INFO -   Volume: (271, 438, 438) voxels, spacing=(0.26, 0.26, 0.26) mm\n",
      "2026-01-15 18:45:57 - INFO -   Volume origin: (-35.230000000000004, -56.940000000000005, -56.940000000000005) mm\n",
      "2026-01-15 18:45:57 - INFO -   Ramp filter window: shepp-logan\n",
      "2026-01-15 18:45:57 - INFO -   Step 1 completed in 0.00s\n",
      "2026-01-15 18:45:57 - INFO - \n",
      "2026-01-15 18:45:57 - INFO - Step 2: Loading projections...\n",
      "2026-01-15 18:45:57 - INFO - Loading projections from: projections.mhd\n",
      "2026-01-15 18:45:59 - INFO - Projections shape after reordering: (1440, 1024, 1024)\n",
      "2026-01-15 18:45:59 - INFO - Projection data type: float32\n",
      "2026-01-15 18:46:00 - INFO - Min: 0.0010, Max: 0.3771, Mean: 0.2589\n",
      "2026-01-15 18:46:00 - INFO -   Step 2 completed in 3.32s\n",
      "2026-01-15 18:46:00 - INFO - \n",
      "2026-01-15 18:46:00 - INFO - Step 3: Running backprojection...\n",
      "2026-01-15 18:46:00 - INFO -   Processing 1440 projections...\n",
      "2026-01-15 18:46:00 - INFO -   Reconstructing volume of shape (271, 438, 438)...\n",
      "2026-01-15 18:46:00 - INFO -   Total voxels to process: 51,989,724\n",
      "2026-01-15 18:46:00 - INFO -   Using GPU backprojector with CPU-side per-angle filtering (streaming)\n",
      "2026-01-15 18:46:00 - INFO -   Starting GPU backprojection with 271×438×438 voxels and 1440 projections\n",
      "2026-01-15 18:46:00 - INFO -     Progress: 1/1440 projections (0.1%)\n",
      "2026-01-15 18:46:30 - INFO -     Progress: 144/1440 projections (10.0%)\n",
      "2026-01-15 18:47:00 - INFO -     Progress: 288/1440 projections (20.0%)\n",
      "2026-01-15 18:47:30 - INFO -     Progress: 432/1440 projections (30.0%)\n",
      "2026-01-15 18:48:01 - INFO -     Progress: 576/1440 projections (40.0%)\n",
      "2026-01-15 18:48:31 - INFO -     Progress: 720/1440 projections (50.0%)\n",
      "2026-01-15 18:49:01 - INFO -     Progress: 864/1440 projections (60.0%)\n",
      "2026-01-15 18:49:31 - INFO -     Progress: 1008/1440 projections (70.0%)\n",
      "2026-01-15 18:50:01 - INFO -     Progress: 1152/1440 projections (80.0%)\n",
      "2026-01-15 18:50:31 - INFO -     Progress: 1296/1440 projections (90.0%)\n",
      "2026-01-15 18:51:01 - INFO -     Progress: 1440/1440 projections (100.0%)\n",
      "2026-01-15 18:51:02 - INFO -     Progress: 1440/1440 projections (100.0%)\n",
      "2026-01-15 18:51:02 - INFO -   Normalizing volume...\n",
      "2026-01-15 18:51:02 - INFO -   GPU backprojection normalization complete\n",
      "2026-01-15 18:51:02 - INFO -   ✓ Reconstruction complete in 301.74 seconds (5.03 minutes)\n",
      "2026-01-15 18:51:02 - INFO -   Performance: 172298 voxels/sec\n",
      "2026-01-15 18:51:02 - INFO - \n",
      "2026-01-15 18:51:02 - INFO - Step 4: Volume statistics\n",
      "2026-01-15 18:51:02 - INFO -   Shape: (271, 438, 438)\n",
      "2026-01-15 18:51:02 - INFO -   Data type: float32\n",
      "2026-01-15 18:51:02 - INFO -   Min:  -0.002125\n",
      "2026-01-15 18:51:02 - INFO -   Max:  0.002126\n",
      "2026-01-15 18:51:02 - INFO -   Mean: -0.000015\n",
      "2026-01-15 18:51:02 - INFO -   Std:  0.000127\n",
      "2026-01-15 18:51:02 - INFO -   Max value location:\n",
      "2026-01-15 18:51:02 - INFO -     Voxel index: (np.int64(152), np.int64(437), np.int64(197))\n",
      "2026-01-15 18:51:02 - INFO -     World coords: (4.42, 56.81, -5.59) mm\n",
      "2026-01-15 18:51:02 - INFO - \n",
      "2026-01-15 18:51:02 - INFO - Step 5: Saving results...\n",
      "2026-01-15 18:51:02 - INFO -   Saved: recon_volume.npy\n",
      "2026-01-15 18:51:02 - INFO - Saved volume to: output/recon_volume.mhd\n",
      "2026-01-15 18:51:03 - INFO - Saved: recon_axial.png\n",
      "2026-01-15 18:51:03 - INFO - Saved: recon_coronal.png\n",
      "2026-01-15 18:51:04 - INFO - Saved: recon_sagittal.png\n",
      "2026-01-15 18:51:04 - INFO -   Step 5 completed in 1.68s\n",
      "2026-01-15 18:51:04 - INFO - \n",
      "2026-01-15 18:51:04 - INFO - ================================================================================\n",
      "2026-01-15 18:51:04 - INFO - ✓ Reconstruction complete! Results saved to: output\n",
      "2026-01-15 18:51:04 - INFO - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Generate unique log filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/training_{timestamp}.log\"\n",
    "\n",
    "print(f\"Starting training in background...\")\n",
    "print(f\"Logs will be written to: {log_file}\")\n",
    "print(f\"To monitor progress: tail -f {log_file}\")\n",
    "print(f\"To check if still running: ps aux | grep 'python main.py'\")\n",
    "\n",
    "# Launch training as detached background process\n",
    "# nohup ensures it continues after SSH disconnect\n",
    "# &> redirects both stdout and stderr to log file\n",
    "# & runs in background\n",
    "# The process will continue even if you close this notebook or disconnect SSH\n",
    "cmd = (\n",
    "    f\"nohup python main.py  \"\n",
    "    f\"& --filter-window hann\"\n",
    "    f\"&> {log_file} &\"\n",
    ")\n",
    "os.system(cmd)\n",
    "\n",
    "print(\"\\n✓ Training launched in background!\")\n",
    "print(f\"\\nUseful commands:\")\n",
    "print(f\"  Monitor live:     tail -f {log_file}\")\n",
    "print(f\"  Check status:     ps aux | grep 'python main.py'\")\n",
    "print(f\"  Kill if needed:   pkill -f 'python main.py'\")\n",
    "print(f\"  GPU usage:        nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376d0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284fec57-66c8-4c11-9e38-7d8b48d50f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring: logs/training_20251222_024019.log\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Monitor the most recent training log\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Find most recent log file\n",
    "log_files = sorted(glob.glob('logs/training_*.log'))\n",
    "if log_files:\n",
    "    latest_log = log_files[-1]\n",
    "    print(f\"Monitoring: {latest_log}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display last 30 lines\n",
    "    with open(latest_log, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-30:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(\"No training logs found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492cecb-a2bc-421e-9182-2b6dc5714bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if still running\n",
    "!ps aux | grep 'python main.py' | grep -v grep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84af0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 15 18:19:25 2026       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.274.02             Driver Version: 535.274.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   42C    P8              25W / 370W |     27MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1884      G   /usr/lib/xorg/Xorg                           11MiB |\n",
      "|    0   N/A  N/A      2027      G   /usr/bin/gnome-shell                          8MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check GPU utilization\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "472688be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping all training processes...\n",
      "✓ Training processes stopped\n",
      "⚠ Some processes still running, try again or use: kill -9 <PID>\n"
     ]
    }
   ],
   "source": [
    "# Stop training if needed (kills all python main.py processes)\n",
    "import subprocess\n",
    "\n",
    "print(\"Stopping all training processes...\")\n",
    "subprocess.run(['pkill', '-f', 'python main.py'])\n",
    "print(\"✓ Training processes stopped\")\n",
    "\n",
    "# Verify\n",
    "result = subprocess.run(['pgrep', '-f', 'python main_wave2D_2branch.py'], capture_output=True)\n",
    "if result.stdout:\n",
    "    print(\"⚠ Some processes still running, try again or use: kill -9 <PID>\")\n",
    "else:\n",
    "    print(\"✓ All training processes terminated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e45792b-9baf-4662-97c8-64a9bdfd427a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3406397356.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    kill -9 2508066\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kill -9 2508066"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
